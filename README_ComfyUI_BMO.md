# MiniMax-Remover BMO - ComfyUI Integration

ğŸ‰ **High-Quality Video Object Removal** 

This is the **BMO** implementation of MiniMax-Remover for ComfyUI that delivers natural, high-quality inpainting results. Based on the official MiniMax-Remover implementation with proper VAE normalization and dimension handling.

## ğŸ”¥ Key Features

- âœ… **Proper VAE Normalization**: Uses official `latents_mean` and `latents_std` from VAE config
- âœ… **Optimized Scheduler**: Properly configured UniPCMultistepScheduler for flow prediction
- âœ… **Dimension Compatibility**: Perfect VAE output vs transformer input alignment
- âœ… **Official Parameters**: Uses optimal defaults (12 steps, 6 iterations)
- âœ… **Natural Results**: Produces solid, realistic inpainting with clean edges

## ğŸ“¥ Installation

***CLONE THE REPO***

### Method 1: Automatic Setup (Recommended)

1. Run the setup script: this will move all the files you need directly into you comfy ui custom nodes section for you. 
```bash
python setup_comfyui_integration_bmo.py
```

2. Follow the prompts to specify your ComfyUI path
3. Restart ComfyUI completely

### Method 2: Manual Installation

1. Copy these files to your ComfyUI custom_nodes directory:
```
ComfyUI/custom_nodes/minimax-remover-bmo/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ minimax_mask_node_bmo.py
â”œâ”€â”€ pipeline_minimax_remover_bmo.py
â””â”€â”€ transformer_minimax_remover.py
â””â”€â”€Models
   â”œâ”€â”€ vae/
   â”‚   â”œâ”€â”€ config.json
   â”‚   â””â”€â”€ diffusion_pytorch_model.safetensors
   â”œâ”€â”€ transformer/
   â”‚   â”œâ”€â”€ config.json
   â”‚   â””â”€â”€ diffusion_pytorch_model.safetensors
   â””â”€â”€ scheduler/
       â””â”€â”€ scheduler_config.json

```

2. Restart ComfyUI

## ğŸš€ Usage

### In ComfyUI:

1. **Add the node**: Look for "MiniMax-Remover (BMO)" in the MiniMax-Remover category

2. **Connect inputs**:
   - `images`: Your video frames as IMAGE type
   - `masks`: Your binary masks as MASK type

3. **Set parameters**:
   - `num_inference_steps`: 12 (official default, good quality/speed balance)
   - `iterations`: 6 (mask expansion iterations, official default)
   - `seed`: Any number for reproducible results
   - `model_path`: Path to your MiniMax models (default: "models/")

4. **Run**: The output will be clean, natural-looking inpainting!

### Model Setup (also shown above with main files)

Place your MiniMax-Remover models in the same custom nodes section as your main files from installation above:
```
ComfyUI/custom_nodes/minimax-remover-bmo/models
â”œâ”€â”€ vae/
â”‚   â”œâ”€â”€ config.json
â”‚   â””â”€â”€ diffusion_pytorch_model.safetensors
â”œâ”€â”€ transformer/
â”‚   â”œâ”€â”€ config.json
â”‚   â””â”€â”€ diffusion_pytorch_model.safetensors
â””â”€â”€ scheduler/
    â””â”€â”€ scheduler_config.json
```

## ğŸ“Š Performance

- **Processing Time**: ~1-2 seconds for 5 frames at 288x528
- **Memory Usage**: Efficient with proper tensor management
- **Quality**: Natural, solid inpainting results

## ğŸ› Troubleshooting

### Poor quality results:
- Ensure you're using the BMO node (latest version)
- Try different seeds  
- Adjust mask expansion (iterations parameter)

### Memory issues:
- Use smaller input resolutions
- Enable model offloading in ComfyUI

## ğŸ“ Example Workflow

1. **Load Video**: Use VHS nodes to load your input video
2. **Create Masks**: Use masking tools or load pre-made masks
3. **Process**: Connect to "MiniMax-Remover (BMO)" node
4. **Output**: Save or preview the cleaned video

## ğŸ¯ Best Practices

- **Resolution**: Works best with resolutions divisible by 16
- **Mask Quality**: Clean, binary masks work best
- **Iterations**: 6-10 for most cases, higher for larger objects
- **Steps**: 12 is optimal, 8-20 range depending on quality needs

## ğŸ”— Links

- [Original MiniMax-Remover Paper](https://arxiv.org/abs/2412.09940)
- [Official Implementation](https://github.com/miraikan-research/MiniMax-Remover)
- [ComfyUI](https://github.com/comfyanonymous/ComfyUI)

---

**Happy inpainting!** ğŸ¨âœ¨ 
